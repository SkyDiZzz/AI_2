{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа №6\n",
    "## Keras. Нейронные сети"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras — это библиотека для Python с открытым исходным кодом, которая позволяет легко создавать нейронные сети. Библиотека совместима с TensorFlow, Microsoft Cognitive Toolkit, Theano и MXNet. Tensorflow и Theano являются наиболее часто используемыми численными платформами на Python для разработки алгоритмов глубокого обучения, но они довольно сложны в использовании.\n",
    "\n",
    "В достаточной степени подробно о keras описано в статье:\n",
    "* https://habr.com/ru/company/ods/blog/325432/\n",
    "\n",
    "Документация Keras доступна по ссылке:\n",
    "* https://keras.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading https://files.pythonhosted.org/packages/7b/14/e4538c2bc3ae9f4ce6f6ce7ef1180da05abc4a617afba798268232b01d0d/tensorflow-1.13.1-cp37-cp37m-win_amd64.whl (63.1MB)\n",
      "Collecting keras-applications>=1.0.6 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
      "Collecting tensorboard<1.14.0,>=1.13.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/0f/39/bdd75b08a6fba41f098b6cb091b9e8c7a80e1b4d679a581a0ccd17b10373/tensorboard-1.13.1-py3-none-any.whl (3.2MB)\n",
      "Collecting astor>=0.6.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/d1/4f/950dfae467b384fc96bc6469de25d832534f6b4441033c39f914efd13418/astor-0.8.0-py2.py3-none-any.whl\n",
      "Collecting protobuf>=3.6.1 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/49/cd/608edf77e6b7cbc6a79dfc33039ee78afac29dfa8e6c894b9ef95b8a5c8c/protobuf-3.8.0-cp37-cp37m-win_amd64.whl (1.0MB)\n",
      "Collecting gast>=0.2.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\users\\skydi\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/8a/48/a76be51647d0eb9f10e2a4511bf3ffb8cc1e6b14e9e4fab46173aa79f981/termcolor-1.1.0.tar.gz\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\skydi\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from tensorflow) (0.33.4)\n",
      "Collecting tensorflow-estimator<1.14.0rc0,>=1.13.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/bb/48/13f49fc3fa0fdf916aa1419013bb8f2ad09674c275b4046d5ee669a46873/tensorflow_estimator-1.13.0-py2.py3-none-any.whl (367kB)\n",
      "Collecting grpcio>=1.8.6 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/f7/bd/171c99a393df51faae5f696c9fedee59c109c4346535fe84450ab0d2cdd6/grpcio-1.21.1-cp37-cp37m-win_amd64.whl (1.6MB)\n",
      "Collecting absl-py>=0.1.6 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/da/3f/9b0355080b81b15ba6a9ffcf1f5ea39e307a2778b2f2dc8694724e8abd5b/absl-py-0.7.1.tar.gz (99kB)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\skydi\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.4)\n",
      "Collecting keras-preprocessing>=1.0.5 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/28/6a/8c1f62c37212d9fc441a7e26736df51ce6f0e38455816445471f10da4f0a/Keras_Preprocessing-1.1.0-py2.py3-none-any.whl (41kB)\n",
      "Requirement already satisfied: h5py in c:\\users\\skydi\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from keras-applications>=1.0.6->tensorflow) (2.9.0)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<1.14.0,>=1.13.0->tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/c0/4e/fd492e91abdc2d2fcb70ef453064d980688762079397f779758e055f6575/Markdown-3.1.1-py2.py3-none-any.whl (87kB)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\skydi\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow) (0.15.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\skydi\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from protobuf>=3.6.1->tensorflow) (41.0.1)\n",
      "Collecting mock>=2.0.0 (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/05/d2/f94e68be6b17f46d2c353564da56e6fb89ef09faeeff3313a046cb810ca9/mock-3.0.5-py2.py3-none-any.whl\n",
      "Building wheels for collected packages: gast, termcolor, absl-py\n",
      "  Building wheel for gast (setup.py): started\n",
      "  Building wheel for gast (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\skydi\\AppData\\Local\\pip\\Cache\\wheels\\5c\\2e\\7e\\a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\skydi\\AppData\\Local\\pip\\Cache\\wheels\\7c\\06\\54\\bc84598ba1daf8f970247f550b175aaaee85f68b4b0c5ab2c6\n",
      "  Building wheel for absl-py (setup.py): started\n",
      "  Building wheel for absl-py (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\skydi\\AppData\\Local\\pip\\Cache\\wheels\\ee\\98\\38\\46cbcc5a93cfea5492d19c38562691ddb23b940176c14f7b48\n",
      "Successfully built gast termcolor absl-py\n",
      "Installing collected packages: keras-applications, protobuf, markdown, absl-py, grpcio, tensorboard, astor, gast, termcolor, mock, tensorflow-estimator, keras-preprocessing, tensorflow\n",
      "Successfully installed absl-py-0.7.1 astor-0.8.0 gast-0.2.2 grpcio-1.21.1 keras-applications-1.0.8 keras-preprocessing-1.1.0 markdown-3.1.1 mock-3.0.5 protobuf-3.8.0 tensorboard-1.13.1 tensorflow-1.13.1 tensorflow-estimator-1.13.0 termcolor-1.1.0\n",
      "Collecting keras\n",
      "  Downloading https://files.pythonhosted.org/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl (312kB)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\skydi\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from keras) (1.16.4)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\skydi\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from keras) (1.12.0)\n",
      "Requirement already satisfied: h5py in c:\\users\\skydi\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from keras) (2.9.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in c:\\users\\skydi\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from keras) (1.0.8)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in c:\\users\\skydi\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from keras) (1.1.0)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\users\\skydi\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from keras) (1.2.1)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\skydi\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from keras) (5.1)\n",
      "Installing collected packages: keras\n",
      "Successfully installed keras-2.2.4\n"
     ]
    }
   ],
   "source": [
    "# Установка Keras (В качестве backend используется tensorflow)\n",
    "!pip install tensorflow\n",
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras as k\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь train_images и train_labels — это тренировочный набор, то есть данные, необходимые для обучения. После обучения модель будет проверяться тестовым (или контрольным) набором, test_images и test_labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изображения хранятся в массивах Numpy, а метки — в массиве цифр от 0 до 9. Изображения и метки находятся в прямом соответствии, один к одному.\n",
    "\n",
    "Рассмотрим обучающие данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И контрольные данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала передадим нейронной сети обучающие данные, ***train_images*** и ***train_labels***. В результате этого сеть обучится сопоставлять изображения с метками. Затем мы предложим сети классифицировать изображения в test_images и проверим точность классификации по меткам из test_labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Архитектура сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\skydi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "network.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основным строительным блоком нейронных сетей является слой (или уровень), модуль обработки данных, который можно рассматривать как фильтр для данных. Он принимает некоторые данные и выводит их в более полезной форме. В частности, слои извлекают представления из подаваемых в них данных, которые, как мы надеемся, будут иметь больше смысла для решаемой задачи. Фактически методика глубокого обучения заключается в объединении простых слоев, реализующих некоторую форму поэтапной очистки данных. Модель глубокого обучения можно сравнить с ситом, состоящим из последовательности фильтров все более тонкой очистки данных — слоев."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном случае наша сеть состоит из последовательности двух слоев Dense, которые являются тесно связанными (их еще называют полносвязными) нейронными Второй (и последний) слой — это 10-переменный слой потерь (softmax layer), возвращающий массив с 10 оценками вероятностей (в сумме дающих 1). Каждая оценка определяет вероятность принадлежности текущего изображения к одному из 10 классов цифр."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы подготовить сеть к обучению, нужно настроить еще три параметра для этапа ***компиляции***:\n",
    "* функцию потерь, которая определяет, как сеть должна оценивать качество своей работы на обучающих данных и, соответственно, как корректировать ее в правильном направлении;\n",
    "* оптимизатор — механизм, с помощью которого сеть будет обновлять себя, опираясь на наблюдаемые данные и функцию потерь;\n",
    "* метрики для мониторинга на этапах обучения и тестирования — здесь нас будет интересовать только точность (доля правильно классифицированных изображений)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Этап компиляции**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.compile(optimizer='rmsprop',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перед обучением выполним предварительную обработку данных, преобразовав их в форму, которую ожидает получить нейронная сеть, и масштабируем их так, чтобы все значения оказались в интервале [0, 1]. Исходные данные — обучающие изображения — хранятся в трехмерном массиве (60000, 28, 28) типа uint8, значениями в котором являются числа в интервале [0, 255]. Мы преобразуем его в массив (60000, 28 * 28) типа float32 со значениями в интервале [0, 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Подготовка меток**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для обучения сети в случае использования библиотеки Keras достаточно вызвать метод fit сети — он пытается адаптировать (fit) модель под обучающие данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\skydi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.2549 - acc: 0.9269\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.1044 - acc: 0.9693\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.0688 - acc: 0.9795\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.0492 - acc: 0.9848\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.0373 - acc: 0.9886\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c14abdeda0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.fit(train_images, train_labels, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В процессе обучения отображаются две величины: потери сети на обучающих данных и точность сети на обучающих данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном случае мы достигли точности 0,989 (98,9%) на обучающих данных. Теперь проверим, как модель распознает контрольный набор:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 23us/step\n",
      "test_acc: 0.9792\n",
      "test_loss: 0.06936034274266567\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = network.evaluate(test_images, test_labels)\n",
    "print('test_acc:', test_acc)\n",
    "print('test_loss:', test_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Точность на контрольном наборе составила 98 % — немного меньше, чем на тренировочном наборе. Эта разница между точностью на тренировочном и контрольном наборах демонстрирует пример переобучения (overfitting), когда модели машинного обучения показывают худшую точность на новом наборе данных по сравнению с тренировочным."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Для отображения объекта, можно воспользоваться следующим кодом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "(train_images_raw, train_labels_raw), (test_images_raw, test_labels_raw) = mnist.load_data()\n",
    "\n",
    "# Получение значения по изображению\n",
    "# Цифра, распознанная нейронной сетью\n",
    "digit = network.predict(test_images[1:2] )[0].argmax()\n",
    "\n",
    "# Действительное изображение\n",
    "digit_raw = test_images_raw[1]\n",
    "\n",
    "print (digit)\n",
    "# Вывод изображения\n",
    "plt.imshow(digit_raw, cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 1\n",
    "\n",
    "С помощью Keras создать нейронную сеть, предсказывающую оценку продукта пользователями по их отзывам, классифицируя ее по двум категориям: положительная или отрицательная. Эта задача называется анализом настроений (сентимент-анализ), и решаться будет с использованием сайта с кинорецензиями IMDb.\n",
    "\n",
    "Спектр настроений обычно подразделяется на положительные, отрицательные и нейтральные категории. С использованием анализа настроений можно, например, прогнозировать мнение клиентов и их отношение к продукту на основе написанных ими обзоров. Поэтому анализ настроений широко применяется к обзорам, опросам, текстам и многому другому.\n",
    "\n",
    "\n",
    "Для выполнения задания необходимо дописывать код в ячейки \"# Ваш код\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как и предыдущий dataset IMDb, уже встроен в Keras. Изначально набор данных представлен в пропорции 50/50 для обучени и тестирования, сразу объединим эти данные после загрузки для последующего разделения в пропорции 80/20:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "(training_data, training_targets), (testing_data, testing_targets) = imdb.load_data(num_words=10000)\n",
    "data = np.concatenate((training_data, testing_data), axis=0)\n",
    "targets = np.concatenate((training_targets, testing_targets), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Изучение данных**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используя np.unique и np.hstack вывести имеющиеся категории и количество уникальных слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Категории:  Counter({1: 25000, 0: 25000})\n",
      "Количество уникальных слов:  49579\n"
     ]
    }
   ],
   "source": [
    "# Ваш код\n",
    "import collections\n",
    "hstack = (np.hstack(targets))\n",
    "uniq = len(np.unique(data))\n",
    "print('Категории: ', collections.Counter(hstack))\n",
    "print('Количество уникальных слов: ', uniq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используя np.mean и np.std вывести среднюю длину обзора и стандартное отклонение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средняя длина отзыва:  234.75892\n",
      "Стандартное отклонение:  172.91149458735703\n"
     ]
    }
   ],
   "source": [
    "length = [len(i) for i in data]\n",
    "# Ваш код\n",
    "print('Средняя длина отзыва: ', np.mean(length))\n",
    "print('Стандартное отклонение: ', np.std(length))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Подготовка данных**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нужно векторизовать каждый обзор и заполнить его нулями, чтобы вектор содержал ровно 10 000 чисел. Это означает, что каждый обзор, который короче 10 000 слов, мы заполняем нулями. Это делается потому, что самый большой обзор имеет почти такой же размер, а каждый элемент входных данных нашей нейронной сети должен иметь одинаковый размер. Также нужно выполнить преобразование переменных в тип float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(sequences, dimension = 10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1\n",
    "    return results\n",
    " \n",
    "data = vectorize(data)\n",
    "targets = np.array(targets).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделите датасет на обучающий и тестировочный наборы.\n",
    "\n",
    "Обучающий набор будет состоять из 40 000 обзоров, тестировочный — из 10 000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 10000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#test_x = # Ваш код\n",
    "#test_y = # Ваш код\n",
    "\n",
    "#train_x = # Ваш код\n",
    "#train_y = # Ваш код\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(data, targets, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 10000)\n",
      "(10000, 10000)\n",
      "(40000,)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape)\n",
    "print(test_x.shape)\n",
    "print(train_y.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Создание и обучение модели**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для предотвращения переобучения используется исключение («dropout»). Обратите внимание, что всегда необходимо использовать коэффициент исключения в диапазоне от 20% до 50%. На каждом слое используется функция «dense» для полного соединения слоев друг с другом. В скрытых слоях будем используем функцию активации «relu». Не бойтесь экспериментировать с другими функциями активации. На выходном слое используем сигмоидную функцию, которая выполняет перенормировку значений в диапазоне от 0 до 1. Обратите внимание, что устанавливаем размер входных элементов датасета равным 10 000, потому что наши обзоры имеют размер до 10 000 целых чисел. Входной слой принимает элементы с размером 10 000, а выдает — с размером 50."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самостоятельно добавьте 1 Dropout(коэффициент 0.2) и Dense слой (50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\skydi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 50)                500050    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 505,201\n",
      "Trainable params: 505,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "# Входной слой\n",
    "model.add(layers.Dense(50, activation = \"relu\", input_shape=(10000, )))\n",
    "\n",
    "# Скрытые слои\n",
    "model.add(layers.Dropout(0.3, noise_shape=None, seed=None))\n",
    "model.add(layers.Dense(50, activation = \"relu\"))\n",
    "\n",
    "# !!! Ваш код !!!\n",
    "\n",
    "model.add(layers.Dropout(0.2, noise_shape=None, seed=None))\n",
    "model.add(layers.Dense(50, activation = \"relu\"))\n",
    "\n",
    "# Выходной слой\n",
    "model.add(layers.Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "# Описание модели\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Выполните компиляцию реализованной модели.**\n",
    "\n",
    "В качестве оптимизатора использовать «adam». \n",
    "\n",
    "В качестве функции потерь используем бинарную кросс-энтропию (binary_crossentropy) (так как мы работаем с бинарной классификацией)\n",
    "\n",
    "В качестве метрики оценки — Accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш код\n",
    "model.compile(loss='binary_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Обучение модели**\n",
    "\n",
    "* Количество эпох - 2\n",
    "* Размер партии - 500\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "40000/40000 [==============================] - 6s 141us/step - loss: 0.4126 - acc: 0.8171\n",
      "Epoch 2/2\n",
      "40000/40000 [==============================] - 5s 115us/step - loss: 0.2161 - acc: 0.9186\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c1794a8978>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ваш код\n",
    "model.fit(train_x, train_y, epochs=2, batch_size=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывести точность и потери модели**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 111us/step\n",
      "Точность:  0.8964\n",
      "Потери:  0.2543269215106964\n"
     ]
    }
   ],
   "source": [
    "# Ваш код\n",
    "test_loss, test_acc = model.evaluate(test_x, test_y)\n",
    "print('Точность: ', test_acc)\n",
    "print('Потери: ', test_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используя модель вывести **настроение для первого отзыва** в тестовом наборе данных и сравнить с действительным"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш код\n",
    "from keras.datasets import imdb\n",
    "(training_data, training_targets), (testing_data, testing_targets) = imdb.load_data(num_words=10000)\n",
    "\n",
    "data1 = np.concatenate((training_data, testing_data), axis=0)\n",
    "targets1 = np.concatenate((training_targets, testing_targets), axis=0)\n",
    "\n",
    "train_x_raw, test_x_raw, train_y_raw, test_y_raw = train_test_split(data1, targets1, test_size=0.2)\n",
    "\n",
    "# Цифра, распознанная нейронной сетью\n",
    "digit1 = model.predict(test_x[1:2] )[0].argmax()\n",
    "\n",
    "# Действительное\n",
    "digit_raw1 = vectorize(test_x_raw).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Настроение в тестовом наборе:  0\n",
      "Настроение в действительном:  0\n"
     ]
    }
   ],
   "source": [
    "#test_x_raw_TEST = vectorize(test_x_raw).astype('int64')\n",
    "print('Настроение в тестовом наборе: ', digit1)\n",
    "print('Настроение в действительном: ', digit_raw1[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
